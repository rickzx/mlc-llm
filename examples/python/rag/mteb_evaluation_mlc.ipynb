{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/cfruan/Documents/mlc-llm', '/Users/cfruan/miniconda3/envs/mlc-chat-venv/lib/python311.zip', '/Users/cfruan/miniconda3/envs/mlc-chat-venv/lib/python3.11', '/Users/cfruan/miniconda3/envs/mlc-chat-venv/lib/python3.11/lib-dynload', '', '/Users/cfruan/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/cfruan/Documents/tvm/python\")\n",
    "sys.path.append(\"/Users/cfruan/Documents/mlc-llm/python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfruan/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mteb import MTEB\n",
    "from mlc_llm.embeddings.embeddings import MLCEmbeddings\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import tvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q0f32, f32 embeddings, 768 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 18:44:29] INFO chat_module.py:379: Using model folder: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC\n",
      "[2024-05-02 18:44:29] INFO chat_module.py:380: Using mlc chat config: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC/mlc-chat-config.json\n",
      "[2024-05-02 18:44:30] INFO MTEB.py:257: \n",
      "\n",
      "## Evaluating 1 tasks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - SciFact, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - SciFact, \u001b[3;38;5;241ms2p\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 18:44:30] INFO MTEB.py:265: \n",
      "\n",
      "********************** Evaluating SciFact **********************\n",
      "[2024-05-02 18:44:30] INFO MTEB.py:290: Loading dataset for SciFact\n",
      "[2024-05-02 18:44:30] INFO AbsTaskRetrieval.py:84: Loading Corpus...\n",
      "[2024-05-02 18:44:31] INFO AbsTaskRetrieval.py:86: Loaded 5183 TEST Documents.\n",
      "[2024-05-02 18:44:31] INFO AbsTaskRetrieval.py:87: Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}\n",
      "[2024-05-02 18:44:31] INFO AbsTaskRetrieval.py:90: Loading Queries...\n",
      "[2024-05-02 18:44:33] ERROR MTEB.py:324: Error while evaluating SciFact: Unable to find 'hf://datasets/mteb/scifact@d56462d0e63a25450459c4f213e49ffdb866f7f9/qrels/test.jsonl' with any supported extension ['.csv', '.tsv', '.json', '.jsonl', '.parquet', '.geoparquet', '.gpq', '.arrow', '.txt', '.tar', '.blp', '.bmp', '.dib', '.bufr', '.cur', '.pcx', '.dcx', '.dds', '.ps', '.eps', '.fit', '.fits', '.fli', '.flc', '.ftc', '.ftu', '.gbr', '.gif', '.grib', '.h5', '.hdf', '.png', '.apng', '.jp2', '.j2k', '.jpc', '.jpf', '.jpx', '.j2c', '.icns', '.ico', '.im', '.iim', '.tif', '.tiff', '.jfif', '.jpe', '.jpg', '.jpeg', '.mpg', '.mpeg', '.msp', '.pcd', '.pxr', '.pbm', '.pgm', '.ppm', '.pnm', '.psd', '.bw', '.rgb', '.rgba', '.sgi', '.ras', '.tga', '.icb', '.vda', '.vst', '.webp', '.wmf', '.emf', '.xbm', '.xpm', '.BLP', '.BMP', '.DIB', '.BUFR', '.CUR', '.PCX', '.DCX', '.DDS', '.PS', '.EPS', '.FIT', '.FITS', '.FLI', '.FLC', '.FTC', '.FTU', '.GBR', '.GIF', '.GRIB', '.H5', '.HDF', '.PNG', '.APNG', '.JP2', '.J2K', '.JPC', '.JPF', '.JPX', '.J2C', '.ICNS', '.ICO', '.IM', '.IIM', '.TIF', '.TIFF', '.JFIF', '.JPE', '.JPG', '.JPEG', '.MPG', '.MPEG', '.MSP', '.PCD', '.PXR', '.PBM', '.PGM', '.PPM', '.PNM', '.PSD', '.BW', '.RGB', '.RGBA', '.SGI', '.RAS', '.TGA', '.ICB', '.VDA', '.VST', '.WEBP', '.WMF', '.EMF', '.XBM', '.XPM', '.aiff', '.au', '.avr', '.caf', '.flac', '.htk', '.svx', '.mat4', '.mat5', '.mpc2k', '.ogg', '.paf', '.pvf', '.raw', '.rf64', '.sd2', '.sds', '.ircam', '.voc', '.w64', '.wav', '.nist', '.wavex', '.wve', '.xi', '.mp3', '.opus', '.AIFF', '.AU', '.AVR', '.CAF', '.FLAC', '.HTK', '.SVX', '.MAT4', '.MAT5', '.MPC2K', '.OGG', '.PAF', '.PVF', '.RAW', '.RF64', '.SD2', '.SDS', '.IRCAM', '.VOC', '.W64', '.WAV', '.NIST', '.WAVEX', '.WVE', '.XI', '.MP3', '.OPUS', '.zip']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find 'hf://datasets/mteb/scifact@d56462d0e63a25450459c4f213e49ffdb866f7f9/qrels/test.jsonl' with any supported extension ['.csv', '.tsv', '.json', '.jsonl', '.parquet', '.geoparquet', '.gpq', '.arrow', '.txt', '.tar', '.blp', '.bmp', '.dib', '.bufr', '.cur', '.pcx', '.dcx', '.dds', '.ps', '.eps', '.fit', '.fits', '.fli', '.flc', '.ftc', '.ftu', '.gbr', '.gif', '.grib', '.h5', '.hdf', '.png', '.apng', '.jp2', '.j2k', '.jpc', '.jpf', '.jpx', '.j2c', '.icns', '.ico', '.im', '.iim', '.tif', '.tiff', '.jfif', '.jpe', '.jpg', '.jpeg', '.mpg', '.mpeg', '.msp', '.pcd', '.pxr', '.pbm', '.pgm', '.ppm', '.pnm', '.psd', '.bw', '.rgb', '.rgba', '.sgi', '.ras', '.tga', '.icb', '.vda', '.vst', '.webp', '.wmf', '.emf', '.xbm', '.xpm', '.BLP', '.BMP', '.DIB', '.BUFR', '.CUR', '.PCX', '.DCX', '.DDS', '.PS', '.EPS', '.FIT', '.FITS', '.FLI', '.FLC', '.FTC', '.FTU', '.GBR', '.GIF', '.GRIB', '.H5', '.HDF', '.PNG', '.APNG', '.JP2', '.J2K', '.JPC', '.JPF', '.JPX', '.J2C', '.ICNS', '.ICO', '.IM', '.IIM', '.TIF', '.TIFF', '.JFIF', '.JPE', '.JPG', '.JPEG', '.MPG', '.MPEG', '.MSP', '.PCD', '.PXR', '.PBM', '.PGM', '.PPM', '.PNM', '.PSD', '.BW', '.RGB', '.RGBA', '.SGI', '.RAS', '.TGA', '.ICB', '.VDA', '.VST', '.WEBP', '.WMF', '.EMF', '.XBM', '.XPM', '.aiff', '.au', '.avr', '.caf', '.flac', '.htk', '.svx', '.mat4', '.mat5', '.mpc2k', '.ogg', '.paf', '.pvf', '.raw', '.rf64', '.sd2', '.sds', '.ircam', '.voc', '.w64', '.wav', '.nist', '.wavex', '.wve', '.xi', '.mp3', '.opus', '.AIFF', '.AU', '.AVR', '.CAF', '.FLAC', '.HTK', '.SVX', '.MAT4', '.MAT5', '.MPC2K', '.OGG', '.PAF', '.PVF', '.RAW', '.RF64', '.SD2', '.SDS', '.IRCAM', '.VOC', '.W64', '.WAV', '.NIST', '.WAVEX', '.WVE', '.XI', '.MP3', '.OPUS', '.zip']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m MyModel()\n\u001b[1;32m     45\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m MTEB(tasks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSciFact\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 46\u001b[0m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults_mteb/mlc_original\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/mteb/evaluation/MTEB.py:328\u001b[0m, in \u001b[0;36mMTEB.run\u001b[0;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    329\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check all the error logs at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m )\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/mteb/evaluation/MTEB.py:292\u001b[0m, in \u001b[0;36mMTEB.run\u001b[0;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m task\u001b[38;5;241m.\u001b[39mcheck_if_dataset_is_superseeded()\n\u001b[0;32m--> 292\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_eval_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# run evaluation\u001b[39;00m\n\u001b[1;32m    295\u001b[0m task_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmteb_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmteb\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# noqa: F405\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmteb_dataset_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    301\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/mteb/abstasks/AbsTaskRetrieval.py:230\u001b[0m, in \u001b[0;36mAbsTaskRetrieval.load_data\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m hf_repo_qrels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    222\u001b[0m     dataset_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-qrels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclarin-knext\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataset_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_splits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_splits\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    225\u001b[0m     corpus, queries, qrels \u001b[38;5;241m=\u001b[39m \u001b[43mHFDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_repo_qrels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_repo_qrels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# Conversion from DataSet\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     queries \u001b[38;5;241m=\u001b[39m {query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]: query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries}\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/mteb/abstasks/AbsTaskRetrieval.py:93\u001b[0m, in \u001b[0;36mHFDataLoader.load\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m     90\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Queries...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_queries()\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_qrels\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# filter queries with no qrels\u001b[39;00m\n\u001b[1;32m     95\u001b[0m qrels_dict \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/mteb/abstasks/AbsTaskRetrieval.py:172\u001b[0m, in \u001b[0;36mHFDataLoader._load_qrels\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_qrels\u001b[39m(\u001b[38;5;28mself\u001b[39m, split):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_repo:\n\u001b[0;32m--> 172\u001b[0m         qrels_ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_repo_qrels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[split]\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         qrels_ds \u001b[38;5;241m=\u001b[39m load_dataset(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    180\u001b[0m             data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqrels_file,\n\u001b[1;32m    181\u001b[0m             delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_in_memory,\n\u001b[1;32m    183\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/load.py:2587\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2582\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2583\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2584\u001b[0m )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2587\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/load.py:2296\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[0;32m-> 2296\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2307\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2308\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2310\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39m_use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[1;32m   2312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/builder.py:374\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_dir\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_kwargs \u001b[38;5;241m=\u001b[39m config_kwargs\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/builder.py:627\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilderConfig must have a name, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuilder_config\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;66;03m# resolve data files if needed\u001b[39;00m\n\u001b[0;32m--> 627\u001b[0m \u001b[43mbuilder_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_data_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDownloadConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# compute the config id that is going to be used for caching\u001b[39;00m\n\u001b[1;32m    633\u001b[0m config_id \u001b[38;5;241m=\u001b[39m builder_config\u001b[38;5;241m.\u001b[39mcreate_config_id(\n\u001b[1;32m    634\u001b[0m     config_kwargs,\n\u001b[1;32m    635\u001b[0m     custom_features\u001b[38;5;241m=\u001b[39mcustom_features,\n\u001b[1;32m    636\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/builder.py:213\u001b[0m, in \u001b[0;36mBuilderConfig._resolve_data_files\u001b[0;34m(self, base_path, download_config)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files, DataFilesPatternsDict):\n\u001b[1;32m    212\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m xjoin(base_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;28;01melse\u001b[39;00m base_path\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/data_files.py:814\u001b[0m, in \u001b[0;36mDataFilesPatternsDict.resolve\u001b[0;34m(self, base_path, download_config)\u001b[0m\n\u001b[1;32m    812\u001b[0m out \u001b[38;5;241m=\u001b[39m DataFilesDict()\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, data_files_patterns_list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 814\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_files_patterns_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/data_files.py:767\u001b[0m, in \u001b[0;36mDataFilesPatternsList.resolve\u001b[0;34m(self, base_path, download_config)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern, allowed_extensions \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_extensions):\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 767\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m         )\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/miniconda3/envs/mlc-chat-venv/lib/python3.11/site-packages/datasets/data_files.py:407\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find 'hf://datasets/mteb/scifact@d56462d0e63a25450459c4f213e49ffdb866f7f9/qrels/test.jsonl' with any supported extension ['.csv', '.tsv', '.json', '.jsonl', '.parquet', '.geoparquet', '.gpq', '.arrow', '.txt', '.tar', '.blp', '.bmp', '.dib', '.bufr', '.cur', '.pcx', '.dcx', '.dds', '.ps', '.eps', '.fit', '.fits', '.fli', '.flc', '.ftc', '.ftu', '.gbr', '.gif', '.grib', '.h5', '.hdf', '.png', '.apng', '.jp2', '.j2k', '.jpc', '.jpf', '.jpx', '.j2c', '.icns', '.ico', '.im', '.iim', '.tif', '.tiff', '.jfif', '.jpe', '.jpg', '.jpeg', '.mpg', '.mpeg', '.msp', '.pcd', '.pxr', '.pbm', '.pgm', '.ppm', '.pnm', '.psd', '.bw', '.rgb', '.rgba', '.sgi', '.ras', '.tga', '.icb', '.vda', '.vst', '.webp', '.wmf', '.emf', '.xbm', '.xpm', '.BLP', '.BMP', '.DIB', '.BUFR', '.CUR', '.PCX', '.DCX', '.DDS', '.PS', '.EPS', '.FIT', '.FITS', '.FLI', '.FLC', '.FTC', '.FTU', '.GBR', '.GIF', '.GRIB', '.H5', '.HDF', '.PNG', '.APNG', '.JP2', '.J2K', '.JPC', '.JPF', '.JPX', '.J2C', '.ICNS', '.ICO', '.IM', '.IIM', '.TIF', '.TIFF', '.JFIF', '.JPE', '.JPG', '.JPEG', '.MPG', '.MPEG', '.MSP', '.PCD', '.PXR', '.PBM', '.PGM', '.PPM', '.PNM', '.PSD', '.BW', '.RGB', '.RGBA', '.SGI', '.RAS', '.TGA', '.ICB', '.VDA', '.VST', '.WEBP', '.WMF', '.EMF', '.XBM', '.XPM', '.aiff', '.au', '.avr', '.caf', '.flac', '.htk', '.svx', '.mat4', '.mat5', '.mpc2k', '.ogg', '.paf', '.pvf', '.raw', '.rf64', '.sd2', '.sds', '.ircam', '.voc', '.w64', '.wav', '.nist', '.wavex', '.wve', '.xi', '.mp3', '.opus', '.AIFF', '.AU', '.AVR', '.CAF', '.FLAC', '.HTK', '.SVX', '.MAT4', '.MAT5', '.MPC2K', '.OGG', '.PAF', '.PVF', '.RAW', '.RF64', '.SD2', '.SDS', '.IRCAM', '.VOC', '.W64', '.WAV', '.NIST', '.WAVEX', '.WVE', '.XI', '.MP3', '.OPUS', '.zip']"
     ]
    }
   ],
   "source": [
    "class MyModel():\n",
    "    def __init__(self):\n",
    "        self.model = MLCEmbeddings(\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC\",\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/libs/snowflake-arctic-embed-m-q0f32-metal.so\",\n",
    "            device=\"auto\",\n",
    "            # debug_dir=\"/Users/cfruan/Documents/mlc-llm-repos/mlc-llm-head/debug\",\n",
    "        )\n",
    "    def encode(self, sentences: list[str], **kwargs: Any):\n",
    "        \"\"\"Encodes the given sentences using the encoder.\n",
    "\n",
    "        Args:\n",
    "            sentences: The sentences to encode.\n",
    "            prompt: The prompt to use. Useful for prompt-based models.\n",
    "            **kwargs: Additional arguments to pass to the encoder.\n",
    "\n",
    "        Returns:\n",
    "            The encoded sentences.\n",
    "        \"\"\"\n",
    "        prompt=\"Represent this sentence for searching relevant passages: \"\n",
    "        queries_with_prefix = [\"{}{}\".format(prompt, i) for i in sentences]\n",
    "        mlc_queries = [\"[CLS] \" + query + \" [SEP]\" for query in queries_with_prefix]\n",
    "\n",
    "        # Max batch size is 128, so we chunk it\n",
    "        print(f\"cur batch size: {len(mlc_queries)}\")\n",
    "        chunk_size = 128\n",
    "        hidden_size = 768\n",
    "        def ceildiv(a, b):\n",
    "            return -(a // -b)\n",
    "        num_chunks = ceildiv(len(mlc_queries), chunk_size)\n",
    "\n",
    "        results = []\n",
    "        for i in tqdm(range(num_chunks)):\n",
    "            start = i * chunk_size\n",
    "            end = min(start + chunk_size, len(mlc_queries))\n",
    "            mlc_queries_chunk_i = mlc_queries[start:end]\n",
    "            query_embeddings_mlc = self.model.embed(mlc_queries_chunk_i).numpy()[:,0]\n",
    "            results.append(query_embeddings_mlc)\n",
    "\n",
    "        results_np = np.vstack(results)\n",
    "        assert results_np.shape == (len(sentences), hidden_size), f\"Got size {query_embeddings_mlc.shape}, expected {(len(sentences), hidden_size)}\"\n",
    "        return results_np\n",
    "\n",
    "model = MyModel()\n",
    "evaluation = MTEB(tasks=[\"SciFact\"])\n",
    "evaluation.run(model, output_folder=\"results_mteb/mlc_original\", eval_splits=[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q4f32_1, f32 embeddings, 768 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 18:55:36] INFO chat_module.py:379: Using model folder: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q4f32_1-MLC\n",
      "[2024-05-02 18:55:36] INFO chat_module.py:380: Using mlc chat config: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q4f32_1-MLC/mlc-chat-config.json\n",
      "[2024-05-02 18:55:36] INFO MTEB.py:257: \n",
      "\n",
      "## Evaluating 1 tasks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - SciFact, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - SciFact, \u001b[3;38;5;241ms2p\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 18:55:36] INFO MTEB.py:265: \n",
      "\n",
      "********************** Evaluating SciFact **********************\n",
      "[2024-05-02 18:55:36] INFO MTEB.py:290: Loading dataset for SciFact\n",
      "[2024-05-02 18:55:36] INFO AbsTaskRetrieval.py:84: Loading Corpus...\n",
      "[2024-05-02 18:55:38] INFO AbsTaskRetrieval.py:86: Loaded 5183 TEST Documents.\n",
      "[2024-05-02 18:55:38] INFO AbsTaskRetrieval.py:87: Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}\n",
      "[2024-05-02 18:55:38] INFO AbsTaskRetrieval.py:90: Loading Queries...\n",
      "[2024-05-02 18:55:40] INFO AbsTaskRetrieval.py:103: Loaded 300 TEST Queries.\n",
      "[2024-05-02 18:55:40] INFO AbsTaskRetrieval.py:104: Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}\n",
      "[2024-05-02 18:55:41] INFO RetrievalEvaluator.py:80: Encoding Queries...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur batch size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.08it/s]\n",
      "[2024-05-02 18:55:42] INFO RetrievalEvaluator.py:92: Sorting Corpus by document length (Longest first)...\n",
      "[2024-05-02 18:55:42] INFO RetrievalEvaluator.py:100: Encoding Corpus in batches... Warning: This might take a while!\n",
      "[2024-05-02 18:55:42] INFO RetrievalEvaluator.py:101: Scoring Function: Cosine Similarity (cos_sim)\n",
      "[2024-05-02 18:55:42] INFO RetrievalEvaluator.py:113: Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur batch size: 5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:49<00:00,  2.67s/it]\n",
      "[2024-05-02 18:57:31] INFO AbsTaskRetrieval.py:277: Time taken to retrieve: 110.63 seconds\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:433: For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@1: 0.5567\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@3: 0.6346\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@5: 0.6632\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@10: 0.6837\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@20: 0.7027\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@100: 0.7144\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: NDCG@1000: 0.7199\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@1: 0.5276\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@3: 0.6050\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@5: 0.6244\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@10: 0.6341\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@20: 0.6401\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@100: 0.6420\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: MAP@1000: 0.6422\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@1: 0.5276\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@3: 0.6877\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@5: 0.7571\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@10: 0.8176\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@20: 0.8897\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@100: 0.9500\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: Recall@1000: 0.9933\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@1: 0.5567\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@3: 0.2500\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@5: 0.1687\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@10: 0.0920\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@20: 0.0503\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@100: 0.0108\n",
      "[2024-05-02 18:57:31] INFO RetrievalEvaluator.py:479: P@1000: 0.0011\n",
      "[2024-05-02 18:57:31] INFO utils.py:75: \n",
      "\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@1: 0.5567\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@3: 0.6283\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@5: 0.6435\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@10: 0.6504\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@20: 0.6547\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@100: 0.6562\n",
      "[2024-05-02 18:57:31] INFO utils.py:94: MRR@1000: 0.6564\n",
      "[2024-05-02 18:57:31] INFO MTEB.py:308: Evaluation for SciFact on test took 110.76 seconds\n",
      "[2024-05-02 18:57:31] INFO MTEB.py:314: Scores: {'ndcg_at_1': 0.55667, 'ndcg_at_3': 0.63463, 'ndcg_at_5': 0.66323, 'ndcg_at_10': 0.68375, 'ndcg_at_20': 0.70269, 'ndcg_at_100': 0.71435, 'ndcg_at_1000': 0.71995, 'map_at_1': 0.52761, 'map_at_3': 0.60502, 'map_at_5': 0.62439, 'map_at_10': 0.6341, 'map_at_20': 0.64011, 'map_at_100': 0.64196, 'map_at_1000': 0.64218, 'recall_at_1': 0.52761, 'recall_at_3': 0.68767, 'recall_at_5': 0.75706, 'recall_at_10': 0.81761, 'recall_at_20': 0.88967, 'recall_at_100': 0.95, 'recall_at_1000': 0.99333, 'precision_at_1': 0.55667, 'precision_at_3': 0.25, 'precision_at_5': 0.16867, 'precision_at_10': 0.092, 'precision_at_20': 0.05033, 'precision_at_100': 0.01077, 'precision_at_1000': 0.00112, 'mrr_at_1': 0.55667, 'mrr_at_3': 0.62833, 'mrr_at_5': 0.6435, 'mrr_at_10': 0.65039, 'mrr_at_20': 0.65468, 'mrr_at_100': 0.65619, 'mrr_at_1000': 0.65638, 'evaluation_time': 110.76}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SciFact': {'mteb_version': '1.7.58',\n",
       "  'dataset_revision': '0228b52cf27578f30900b9e5271d331663a030d7',\n",
       "  'mteb_dataset_name': 'SciFact',\n",
       "  'test': {'ndcg_at_1': 0.55667,\n",
       "   'ndcg_at_3': 0.63463,\n",
       "   'ndcg_at_5': 0.66323,\n",
       "   'ndcg_at_10': 0.68375,\n",
       "   'ndcg_at_20': 0.70269,\n",
       "   'ndcg_at_100': 0.71435,\n",
       "   'ndcg_at_1000': 0.71995,\n",
       "   'map_at_1': 0.52761,\n",
       "   'map_at_3': 0.60502,\n",
       "   'map_at_5': 0.62439,\n",
       "   'map_at_10': 0.6341,\n",
       "   'map_at_20': 0.64011,\n",
       "   'map_at_100': 0.64196,\n",
       "   'map_at_1000': 0.64218,\n",
       "   'recall_at_1': 0.52761,\n",
       "   'recall_at_3': 0.68767,\n",
       "   'recall_at_5': 0.75706,\n",
       "   'recall_at_10': 0.81761,\n",
       "   'recall_at_20': 0.88967,\n",
       "   'recall_at_100': 0.95,\n",
       "   'recall_at_1000': 0.99333,\n",
       "   'precision_at_1': 0.55667,\n",
       "   'precision_at_3': 0.25,\n",
       "   'precision_at_5': 0.16867,\n",
       "   'precision_at_10': 0.092,\n",
       "   'precision_at_20': 0.05033,\n",
       "   'precision_at_100': 0.01077,\n",
       "   'precision_at_1000': 0.00112,\n",
       "   'mrr_at_1': 0.55667,\n",
       "   'mrr_at_3': 0.62833,\n",
       "   'mrr_at_5': 0.6435,\n",
       "   'mrr_at_10': 0.65039,\n",
       "   'mrr_at_20': 0.65468,\n",
       "   'mrr_at_100': 0.65619,\n",
       "   'mrr_at_1000': 0.65638,\n",
       "   'evaluation_time': 110.76}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel():\n",
    "    def __init__(self):\n",
    "        self.model = MLCEmbeddings(\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q4f32_1-MLC\",\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/libs/snowflake-arctic-embed-m-q4f32_1-metal.so\",\n",
    "            device=\"auto\",\n",
    "            # debug_dir=\"/Users/cfruan/Documents/mlc-llm-repos/mlc-llm-head/debug\",\n",
    "        )\n",
    "    def encode(self, sentences: list[str], **kwargs: Any):\n",
    "        \"\"\"Encodes the given sentences using the encoder.\n",
    "\n",
    "        Args:\n",
    "            sentences: The sentences to encode.\n",
    "            prompt: The prompt to use. Useful for prompt-based models.\n",
    "            **kwargs: Additional arguments to pass to the encoder.\n",
    "\n",
    "        Returns:\n",
    "            The encoded sentences.\n",
    "        \"\"\"\n",
    "        prompt=\"Represent this sentence for searching relevant passages: \"\n",
    "        queries_with_prefix = [\"{}{}\".format(prompt, i) for i in sentences]\n",
    "        mlc_queries = [\"[CLS] \" + query + \" [SEP]\" for query in queries_with_prefix]\n",
    "\n",
    "        # Max batch size is 128, so we chunk it\n",
    "        print(f\"cur batch size: {len(mlc_queries)}\")\n",
    "        chunk_size = 128\n",
    "        hidden_size = 768\n",
    "        def ceildiv(a, b):\n",
    "            return -(a // -b)\n",
    "        num_chunks = ceildiv(len(mlc_queries), chunk_size)\n",
    "\n",
    "        results = []\n",
    "        for i in tqdm(range(num_chunks)):\n",
    "            start = i * chunk_size\n",
    "            end = min(start + chunk_size, len(mlc_queries))\n",
    "            mlc_queries_chunk_i = mlc_queries[start:end]\n",
    "            query_embeddings_mlc = self.model.embed(mlc_queries_chunk_i).numpy()[:,0]\n",
    "            results.append(query_embeddings_mlc)\n",
    "\n",
    "        results_np = np.vstack(results)\n",
    "        assert results_np.shape == (len(sentences), hidden_size), f\"Got size {query_embeddings_mlc.shape}, expected {(len(sentences), hidden_size)}\"\n",
    "        return results_np\n",
    "\n",
    "model = MyModel()\n",
    "evaluation = MTEB(tasks=[\"SciFact\"])\n",
    "evaluation.run(model, output_folder=\"results_mteb/mlc_q4f32_1\", eval_splits=[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q0f32, binary embeddings, 768 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 18:58:41] INFO chat_module.py:379: Using model folder: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC\n",
      "[2024-05-02 18:58:41] INFO chat_module.py:380: Using mlc chat config: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC/mlc-chat-config.json\n",
      "[2024-05-02 18:58:41] INFO MTEB.py:257: \n",
      "\n",
      "## Evaluating 1 tasks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - SciFact, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - SciFact, \u001b[3;38;5;241ms2p\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 18:58:41] INFO MTEB.py:265: \n",
      "\n",
      "********************** Evaluating SciFact **********************\n",
      "[2024-05-02 18:58:41] INFO MTEB.py:290: Loading dataset for SciFact\n",
      "[2024-05-02 18:58:41] INFO AbsTaskRetrieval.py:84: Loading Corpus...\n",
      "[2024-05-02 18:58:42] INFO AbsTaskRetrieval.py:86: Loaded 5183 TEST Documents.\n",
      "[2024-05-02 18:58:42] INFO AbsTaskRetrieval.py:87: Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}\n",
      "[2024-05-02 18:58:42] INFO AbsTaskRetrieval.py:90: Loading Queries...\n",
      "[2024-05-02 18:58:44] INFO AbsTaskRetrieval.py:103: Loaded 300 TEST Queries.\n",
      "[2024-05-02 18:58:44] INFO AbsTaskRetrieval.py:104: Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}\n",
      "[2024-05-02 18:58:44] INFO RetrievalEvaluator.py:80: Encoding Queries...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur batch size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.10it/s]\n",
      "[2024-05-02 18:58:45] INFO RetrievalEvaluator.py:92: Sorting Corpus by document length (Longest first)...\n",
      "[2024-05-02 18:58:45] INFO RetrievalEvaluator.py:100: Encoding Corpus in batches... Warning: This might take a while!\n",
      "[2024-05-02 18:58:45] INFO RetrievalEvaluator.py:101: Scoring Function: Hamming distance (hamming_distance)\n",
      "[2024-05-02 18:58:45] INFO RetrievalEvaluator.py:113: Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur batch size: 5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:46<00:00,  2.59s/it]\n",
      "[2024-05-02 19:00:32] INFO AbsTaskRetrieval.py:277: Time taken to retrieve: 107.65 seconds\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:433: For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@1: 0.5000\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@3: 0.5536\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@5: 0.5784\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@10: 0.6123\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@20: 0.6266\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@100: 0.6438\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: NDCG@1000: 0.6552\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@1: 0.4751\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@3: 0.5310\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@5: 0.5472\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@10: 0.5625\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@20: 0.5669\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@100: 0.5697\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: MAP@1000: 0.5701\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@1: 0.4751\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@3: 0.5928\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@5: 0.6517\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@10: 0.7501\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@20: 0.8049\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@100: 0.8933\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: Recall@1000: 0.9833\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@1: 0.5000\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@3: 0.2122\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@5: 0.1447\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@10: 0.0847\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@20: 0.0457\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@100: 0.0102\n",
      "[2024-05-02 19:00:32] INFO RetrievalEvaluator.py:479: P@1000: 0.0011\n",
      "[2024-05-02 19:00:32] INFO utils.py:75: \n",
      "\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@1: 0.5000\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@3: 0.5528\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@5: 0.5664\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@10: 0.5800\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@20: 0.5828\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@100: 0.5850\n",
      "[2024-05-02 19:00:32] INFO utils.py:94: MRR@1000: 0.5853\n",
      "[2024-05-02 19:00:32] INFO MTEB.py:308: Evaluation for SciFact on test took 107.80 seconds\n",
      "[2024-05-02 19:00:32] INFO MTEB.py:314: Scores: {'ndcg_at_1': 0.5, 'ndcg_at_3': 0.55363, 'ndcg_at_5': 0.57841, 'ndcg_at_10': 0.61231, 'ndcg_at_20': 0.62662, 'ndcg_at_100': 0.64377, 'ndcg_at_1000': 0.65521, 'map_at_1': 0.47511, 'map_at_3': 0.53102, 'map_at_5': 0.54721, 'map_at_10': 0.56252, 'map_at_20': 0.56694, 'map_at_100': 0.56972, 'map_at_1000': 0.57014, 'recall_at_1': 0.47511, 'recall_at_3': 0.59283, 'recall_at_5': 0.65167, 'recall_at_10': 0.75011, 'recall_at_20': 0.80494, 'recall_at_100': 0.89333, 'recall_at_1000': 0.98333, 'precision_at_1': 0.5, 'precision_at_3': 0.21222, 'precision_at_5': 0.14467, 'precision_at_10': 0.08467, 'precision_at_20': 0.04567, 'precision_at_100': 0.0102, 'precision_at_1000': 0.00111, 'mrr_at_1': 0.5, 'mrr_at_3': 0.55278, 'mrr_at_5': 0.56644, 'mrr_at_10': 0.58, 'mrr_at_20': 0.58283, 'mrr_at_100': 0.585, 'mrr_at_1000': 0.58534, 'evaluation_time': 107.8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SciFact': {'mteb_version': '1.7.58',\n",
       "  'dataset_revision': '0228b52cf27578f30900b9e5271d331663a030d7',\n",
       "  'mteb_dataset_name': 'SciFact',\n",
       "  'test': {'ndcg_at_1': 0.5,\n",
       "   'ndcg_at_3': 0.55363,\n",
       "   'ndcg_at_5': 0.57841,\n",
       "   'ndcg_at_10': 0.61231,\n",
       "   'ndcg_at_20': 0.62662,\n",
       "   'ndcg_at_100': 0.64377,\n",
       "   'ndcg_at_1000': 0.65521,\n",
       "   'map_at_1': 0.47511,\n",
       "   'map_at_3': 0.53102,\n",
       "   'map_at_5': 0.54721,\n",
       "   'map_at_10': 0.56252,\n",
       "   'map_at_20': 0.56694,\n",
       "   'map_at_100': 0.56972,\n",
       "   'map_at_1000': 0.57014,\n",
       "   'recall_at_1': 0.47511,\n",
       "   'recall_at_3': 0.59283,\n",
       "   'recall_at_5': 0.65167,\n",
       "   'recall_at_10': 0.75011,\n",
       "   'recall_at_20': 0.80494,\n",
       "   'recall_at_100': 0.89333,\n",
       "   'recall_at_1000': 0.98333,\n",
       "   'precision_at_1': 0.5,\n",
       "   'precision_at_3': 0.21222,\n",
       "   'precision_at_5': 0.14467,\n",
       "   'precision_at_10': 0.08467,\n",
       "   'precision_at_20': 0.04567,\n",
       "   'precision_at_100': 0.0102,\n",
       "   'precision_at_1000': 0.00111,\n",
       "   'mrr_at_1': 0.5,\n",
       "   'mrr_at_3': 0.55278,\n",
       "   'mrr_at_5': 0.56644,\n",
       "   'mrr_at_10': 0.58,\n",
       "   'mrr_at_20': 0.58283,\n",
       "   'mrr_at_100': 0.585,\n",
       "   'mrr_at_1000': 0.58534,\n",
       "   'evaluation_time': 107.8}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel():\n",
    "    def __init__(self):\n",
    "        self.model = MLCEmbeddings(\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC\",\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/libs/snowflake-arctic-embed-m-q0f32-metal.so\",\n",
    "            device=\"auto\",\n",
    "            # debug_dir=\"/Users/cfruan/Documents/mlc-llm-repos/mlc-llm-head/debug\",\n",
    "        )\n",
    "    def encode(self, sentences: list[str], **kwargs: Any):\n",
    "        \"\"\"Encodes the given sentences using the encoder.\n",
    "\n",
    "        Args:\n",
    "            sentences: The sentences to encode.\n",
    "            prompt: The prompt to use. Useful for prompt-based models.\n",
    "            **kwargs: Additional arguments to pass to the encoder.\n",
    "\n",
    "        Returns:\n",
    "            The encoded sentences.\n",
    "        \"\"\"\n",
    "        prompt=\"Represent this sentence for searching relevant passages: \"\n",
    "        queries_with_prefix = [\"{}{}\".format(prompt, i) for i in sentences]\n",
    "        mlc_queries = [\"[CLS] \" + query + \" [SEP]\" for query in queries_with_prefix]\n",
    "\n",
    "        # Max batch size is 128, so we chunk it\n",
    "        print(f\"cur batch size: {len(mlc_queries)}\")\n",
    "        chunk_size = 128\n",
    "        hidden_size = 768\n",
    "        def ceildiv(a, b):\n",
    "            return -(a // -b)\n",
    "        num_chunks = ceildiv(len(mlc_queries), chunk_size)\n",
    "\n",
    "        results = []\n",
    "        for i in tqdm(range(num_chunks)):\n",
    "            start = i * chunk_size\n",
    "            end = min(start + chunk_size, len(mlc_queries))\n",
    "            mlc_queries_chunk_i = mlc_queries[start:end]\n",
    "            query_embeddings_mlc = self.model.embed_binary(mlc_queries_chunk_i).numpy().astype(np.int8)\n",
    "\n",
    "            results.append(query_embeddings_mlc)\n",
    "\n",
    "        results_np = np.vstack(results)\n",
    "        assert results_np.shape == (len(sentences), hidden_size), f\"Got size {query_embeddings_mlc.shape}, expected {(len(sentences), hidden_size)}\"\n",
    "        return results_np\n",
    "\n",
    "model = MyModel()\n",
    "evaluation = MTEB(tasks=[\"SciFact\"])\n",
    "evaluation.run(model, output_folder=\"results_mteb/mlc_binary\", eval_splits=[\"test\"], score_function=\"hamming_distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q0f32, int8 embeddings, 768 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 19:52:55] INFO chat_module.py:379: Using model folder: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC\n",
      "[2024-05-02 19:52:55] INFO chat_module.py:380: Using mlc chat config: /Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC/mlc-chat-config.json\n",
      "[2024-05-02 19:52:55] INFO MTEB.py:257: \n",
      "\n",
      "## Evaluating 1 tasks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - SciFact, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - SciFact, \u001b[3;38;5;241ms2p\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-02 19:52:55] INFO MTEB.py:265: \n",
      "\n",
      "********************** Evaluating SciFact **********************\n",
      "[2024-05-02 19:52:55] INFO MTEB.py:290: Loading dataset for SciFact\n",
      "[2024-05-02 19:52:55] INFO AbsTaskRetrieval.py:84: Loading Corpus...\n",
      "[2024-05-02 19:52:56] INFO AbsTaskRetrieval.py:86: Loaded 5183 TEST Documents.\n",
      "[2024-05-02 19:52:56] INFO AbsTaskRetrieval.py:87: Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}\n",
      "[2024-05-02 19:52:56] INFO AbsTaskRetrieval.py:90: Loading Queries...\n",
      "[2024-05-02 19:52:58] INFO AbsTaskRetrieval.py:103: Loaded 300 TEST Queries.\n",
      "[2024-05-02 19:52:58] INFO AbsTaskRetrieval.py:104: Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}\n",
      "[2024-05-02 19:52:58] INFO RetrievalEvaluator.py:80: Encoding Queries...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur batch size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.06it/s]\n",
      "[2024-05-02 19:52:59] INFO RetrievalEvaluator.py:92: Sorting Corpus by document length (Longest first)...\n",
      "[2024-05-02 19:52:59] INFO RetrievalEvaluator.py:100: Encoding Corpus in batches... Warning: This might take a while!\n",
      "[2024-05-02 19:52:59] INFO RetrievalEvaluator.py:101: Scoring Function: Cosine Similarity (cos_sim)\n",
      "[2024-05-02 19:52:59] INFO RetrievalEvaluator.py:113: Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur batch size: 5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:47<00:00,  2.61s/it]\n",
      "[2024-05-02 19:54:46] INFO AbsTaskRetrieval.py:277: Time taken to retrieve: 108.22 seconds\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:433: For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@1: 0.5900\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@3: 0.6745\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@5: 0.6878\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@10: 0.7177\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@20: 0.7314\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@100: 0.7407\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: NDCG@1000: 0.7463\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@1: 0.5609\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@3: 0.6436\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@5: 0.6540\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@10: 0.6686\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@20: 0.6727\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@100: 0.6743\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: MAP@1000: 0.6745\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@1: 0.5609\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@3: 0.7327\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@5: 0.7673\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@10: 0.8526\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@20: 0.9059\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@100: 0.9533\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: Recall@1000: 0.9967\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:477: \n",
      "\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@1: 0.5900\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@3: 0.2667\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@5: 0.1700\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@10: 0.0963\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@20: 0.0512\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@100: 0.0108\n",
      "[2024-05-02 19:54:46] INFO RetrievalEvaluator.py:479: P@1000: 0.0011\n",
      "[2024-05-02 19:54:46] INFO utils.py:75: \n",
      "\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@1: 0.5900\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@3: 0.6644\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@5: 0.6714\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@10: 0.6827\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@20: 0.6858\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@100: 0.6868\n",
      "[2024-05-02 19:54:46] INFO utils.py:94: MRR@1000: 0.6870\n",
      "[2024-05-02 19:54:46] INFO MTEB.py:308: Evaluation for SciFact on test took 108.35 seconds\n",
      "[2024-05-02 19:54:46] INFO MTEB.py:314: Scores: {'ndcg_at_1': 0.59, 'ndcg_at_3': 0.67449, 'ndcg_at_5': 0.68781, 'ndcg_at_10': 0.71765, 'ndcg_at_20': 0.73143, 'ndcg_at_100': 0.74069, 'ndcg_at_1000': 0.74632, 'map_at_1': 0.56094, 'map_at_3': 0.64359, 'map_at_5': 0.65399, 'map_at_10': 0.6686, 'map_at_20': 0.67274, 'map_at_100': 0.67432, 'map_at_1000': 0.67455, 'recall_at_1': 0.56094, 'recall_at_3': 0.73267, 'recall_at_5': 0.76733, 'recall_at_10': 0.85256, 'recall_at_20': 0.90589, 'recall_at_100': 0.95333, 'recall_at_1000': 0.99667, 'precision_at_1': 0.59, 'precision_at_3': 0.26667, 'precision_at_5': 0.17, 'precision_at_10': 0.09633, 'precision_at_20': 0.05117, 'precision_at_100': 0.01083, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.59, 'mrr_at_3': 0.66444, 'mrr_at_5': 0.67144, 'mrr_at_10': 0.68268, 'mrr_at_20': 0.6858, 'mrr_at_100': 0.68678, 'mrr_at_1000': 0.68701, 'evaluation_time': 108.35}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SciFact': {'mteb_version': '1.7.58',\n",
       "  'dataset_revision': '0228b52cf27578f30900b9e5271d331663a030d7',\n",
       "  'mteb_dataset_name': 'SciFact',\n",
       "  'test': {'ndcg_at_1': 0.59,\n",
       "   'ndcg_at_3': 0.67449,\n",
       "   'ndcg_at_5': 0.68781,\n",
       "   'ndcg_at_10': 0.71765,\n",
       "   'ndcg_at_20': 0.73143,\n",
       "   'ndcg_at_100': 0.74069,\n",
       "   'ndcg_at_1000': 0.74632,\n",
       "   'map_at_1': 0.56094,\n",
       "   'map_at_3': 0.64359,\n",
       "   'map_at_5': 0.65399,\n",
       "   'map_at_10': 0.6686,\n",
       "   'map_at_20': 0.67274,\n",
       "   'map_at_100': 0.67432,\n",
       "   'map_at_1000': 0.67455,\n",
       "   'recall_at_1': 0.56094,\n",
       "   'recall_at_3': 0.73267,\n",
       "   'recall_at_5': 0.76733,\n",
       "   'recall_at_10': 0.85256,\n",
       "   'recall_at_20': 0.90589,\n",
       "   'recall_at_100': 0.95333,\n",
       "   'recall_at_1000': 0.99667,\n",
       "   'precision_at_1': 0.59,\n",
       "   'precision_at_3': 0.26667,\n",
       "   'precision_at_5': 0.17,\n",
       "   'precision_at_10': 0.09633,\n",
       "   'precision_at_20': 0.05117,\n",
       "   'precision_at_100': 0.01083,\n",
       "   'precision_at_1000': 0.00113,\n",
       "   'mrr_at_1': 0.59,\n",
       "   'mrr_at_3': 0.66444,\n",
       "   'mrr_at_5': 0.67144,\n",
       "   'mrr_at_10': 0.68268,\n",
       "   'mrr_at_20': 0.6858,\n",
       "   'mrr_at_100': 0.68678,\n",
       "   'mrr_at_1000': 0.68701,\n",
       "   'evaluation_time': 108.35}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel():\n",
    "    def __init__(self):\n",
    "        self.model = MLCEmbeddings(\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/snowflake-arctic-embed-m-q0f32-MLC\",\n",
    "            \"/Users/cfruan/Documents/mlc-llm/dist/libs/snowflake-arctic-embed-m-q0f32-metal.so\",\n",
    "            device=\"auto\",\n",
    "            # debug_dir=\"/Users/cfruan/Documents/mlc-llm-repos/mlc-llm-head/debug\",\n",
    "        )\n",
    "        self.ranges = None\n",
    "    def encode(self, sentences: list[str], **kwargs: Any):\n",
    "        \"\"\"Encodes the given sentences using the encoder.\n",
    "\n",
    "        Args:\n",
    "            sentences: The sentences to encode.\n",
    "            prompt: The prompt to use. Useful for prompt-based models.\n",
    "            **kwargs: Additional arguments to pass to the encoder.\n",
    "\n",
    "        Returns:\n",
    "            The encoded sentences.\n",
    "        \"\"\"\n",
    "        prompt=\"Represent this sentence for searching relevant passages: \"\n",
    "        queries_with_prefix = [\"{}{}\".format(prompt, i) for i in sentences]\n",
    "        mlc_queries = [\"[CLS] \" + query + \" [SEP]\" for query in queries_with_prefix]\n",
    "\n",
    "        # Max batch size is 128, so we chunk it\n",
    "        print(f\"cur batch size: {len(mlc_queries)}\")\n",
    "        chunk_size = 128\n",
    "        hidden_size = 768\n",
    "        def ceildiv(a, b):\n",
    "            return -(a // -b)\n",
    "        num_chunks = ceildiv(len(mlc_queries), chunk_size)\n",
    "\n",
    "        results = []\n",
    "        for i in tqdm(range(num_chunks)):\n",
    "            start = i * chunk_size\n",
    "            end = min(start + chunk_size, len(mlc_queries))\n",
    "            mlc_queries_chunk_i = mlc_queries[start:end]\n",
    "            query_embeddings_mlc = self.model.embed(mlc_queries_chunk_i).numpy()[:,0]\n",
    "            query_embeddings_mlc_tvm = tvm.nd.array(query_embeddings_mlc, device=self.model.device)\n",
    "            if self.ranges is None:\n",
    "                self.ranges = np.vstack((np.min(query_embeddings_mlc, axis=0), np.max(query_embeddings_mlc, axis=0)))\n",
    "            query_int8_mlc = self.model.quantize_embeddings(query_embeddings_mlc_tvm, \"int8\", ranges=self.ranges).numpy()\n",
    "            results.append(query_int8_mlc.astype(\"float32\"))\n",
    "\n",
    "        results_np = np.vstack(results)\n",
    "        assert results_np.shape == (len(sentences), hidden_size), f\"Got size {query_embeddings_mlc.shape}, expected {(len(sentences), hidden_size)}\"\n",
    "        return results_np\n",
    "\n",
    "model = MyModel()\n",
    "evaluation = MTEB(tasks=[\"SciFact\"])\n",
    "evaluation.run(model, output_folder=\"results_mteb/mlc_int8\", eval_splits=[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-chat-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
